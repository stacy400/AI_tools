{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ISnOWBUx3Nwl",
        "outputId": "0e3580ef-46dd-4b81-984e-b5b9a85c69fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking for existing model...\n",
            "❌ Model not found. Training new model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.5337 - val_accuracy: 0.9589 - val_loss: 0.1346\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1608 - val_accuracy: 0.9699 - val_loss: 0.1005\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9645 - loss: 0.1181 - val_accuracy: 0.9729 - val_loss: 0.0899\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.0976 - val_accuracy: 0.9712 - val_loss: 0.0893\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.0828 - val_accuracy: 0.9766 - val_loss: 0.0797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 Model saved to model/mnist_model.h5\n",
            "🎉 Training complete! Test Accuracy: 0.9766\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://818fb9e65555c2e7c8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://818fb9e65555c2e7c8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: No image found in dictionary.\n"
          ]
        }
      ],
      "source": [
        "# app.py - Trains MNIST on first launch, then reuses model\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# Define model path\n",
        "MODEL_DIR = \"model\"\n",
        "MODEL_PATH = os.path.join(MODEL_DIR, \"mnist_model.h5\")\n",
        "\n",
        "# Create model directory if not exists\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Checking for existing model...\")\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    print(\" Loading pre-trained model...\")\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    model.summary()\n",
        "else:\n",
        "    print(\" Model not found. Training new model...\")\n",
        "    # Load and preprocess data\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Build model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train (fast: 5 epochs on full MNIST)\n",
        "    print(\"Starting training...\")\n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "    # Save model\n",
        "    model.save(MODEL_PATH)\n",
        "    print(f\" Model saved to {MODEL_PATH}\")\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Training complete! Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "def preprocess_image(image):\n",
        "    if image is None:\n",
        "        print(\"Warning: Received None as image input.\")\n",
        "        return None\n",
        "\n",
        "    # Handle Gradio ImageEditor output (dict with 'image' key)\n",
        "    if isinstance(image, dict):\n",
        "        image = image.get('image', None)\n",
        "        if image is None:\n",
        "            print(\"Warning: No image found in dictionary.\")\n",
        "            return None\n",
        "\n",
        "    # Handle Gradio UploadButton output (file path or PIL image)\n",
        "    if isinstance(image, str):\n",
        "        try:\n",
        "            image = Image.open(image)\n",
        "            image = np.array(image.convert('L'))\n",
        "        except Exception as e:\n",
        "            print(f\"Error opening uploaded image: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Convert PIL image to NumPy array if needed\n",
        "    if hasattr(image, 'convert'):\n",
        "        image = np.array(image.convert('L'))\n",
        "\n",
        "    # Ensure it's a grayscale image\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    elif len(image.shape) == 2:\n",
        "        gray = image\n",
        "    else:\n",
        "        print(f\"Warning: Unexpected image shape {image.shape}\")\n",
        "        return None\n",
        "\n",
        "    # Resize to 28x28\n",
        "    resized = cv2.resize(gray, (28, 28), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Invert: black strokes on white background -> white on black for MNIST\n",
        "    # Check if background is bright (white canvas with black pen)\n",
        "    if resized.mean() > 128:\n",
        "        resized = 255 - resized\n",
        "\n",
        "    # Normalize\n",
        "    normalized = resized.astype('float32') / 255.0\n",
        "\n",
        "    print(\"Preprocessed image shape:\", normalized.shape)\n",
        "    print(\"Preprocessed image mean:\", normalized.mean())\n",
        "\n",
        "    return normalized\n",
        "\n",
        "def predict_digit(image):\n",
        "    processed = preprocess_image(image)\n",
        "    if processed is None:\n",
        "        return {str(i): 0.0 for i in range(10)}, pd.DataFrame(columns=['Digit', 'Probability'])\n",
        "\n",
        "    # Reshape for model input: (1, 28, 28)\n",
        "    input_tensor = np.expand_dims(processed, axis=0)\n",
        "    preds = model.predict(input_tensor, verbose=0)[0]\n",
        "\n",
        "    # Format output for Gradio Label component\n",
        "    predictions_dict = {str(i): float(preds[i]) for i in range(10)}\n",
        "\n",
        "    # Format output for Gradio BarPlot component\n",
        "    barplot_data = [[str(i), float(preds[i])] for i in range(10)]\n",
        "    df = pd.DataFrame(barplot_data, columns=['Digit', 'Probability'])\n",
        "\n",
        "    return predictions_dict, df\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"#  Kilele AI Tutor: Handwritten Digit Recognition\")\n",
        "    gr.Markdown(\"Draw or upload a digit (0–9). Our AI will classify it!\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            sketchpad = gr.ImageEditor(\n",
        "                label=\"Draw Digit\",\n",
        "                image_mode=\"L\",\n",
        "                canvas_size=(280, 280),\n",
        "                brush=gr.Brush(\n",
        "                    default_size=15,\n",
        "                    colors=[\"#000000\"],\n",
        "                    default_color=\"#000000\",\n",
        "                    color_mode=\"fixed\"\n",
        "                ),\n",
        "                eraser=gr.Eraser(default_size=15),\n",
        "                sources=[\"upload\"],\n",
        "                type=\"numpy\",\n",
        "                layers=False,\n",
        "                transforms=[]\n",
        "            )\n",
        "            upload_btn = gr.UploadButton(\"📁 Upload Image\", file_types=[\"image\"])\n",
        "            clear_btn = gr.Button(\"🧹 Clear Canvas\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_label = gr.Label(label=\"Prediction\", num_top_classes=1)\n",
        "            output_bars = gr.BarPlot(\n",
        "                label=\"Confidence Scores\",\n",
        "                x=\"Digit\",\n",
        "                y=\"Probability\",\n",
        "                vertical=False,\n",
        "                height=200\n",
        "            )\n",
        "\n",
        "    # Connect events\n",
        "    sketchpad.change(predict_digit, inputs=sketchpad, outputs=[output_label, output_bars])\n",
        "    upload_btn.upload(predict_digit, inputs=upload_btn, outputs=[output_label, output_bars])\n",
        "    clear_btn.click(lambda: None, inputs=None, outputs=sketchpad)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
